{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with PyTorch Tensors\n",
    "\n",
    "This tutorial is adapted from [the PyTorch Tutorials](https://pytorch.org/tutorials/), valuable references for learning the fundamentals of Deep Learning in PyTorch. We highly recommend exploring other tutorials for deeper understanding and additional topics.\n",
    "\n",
    "In this tutorial, you will learn the following:\n",
    "- Utilizing PyTorch tensors to encode inputs, outputs, and parameters for deep learning models.\n",
    "\n",
    "Tensors closely resemble arrays and matrices and serve as a specialized data structure. In PyTorch, tensors play a crucial role in representing the inputs, outputs, and parameters of a model.\n",
    "\n",
    "Tensors share similarities with NumPy's ndarrays, but they offer the advantage of being capable of running on GPUs or other specialized hardware for accelerated computing. If you are acquainted with ndarrays, navigating the Tensor API should feel familiar. For those unfamiliar, this brief API walkthrough will guide you through the essentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Importing the PyTorch library\n",
    "import torch\n",
    "\n",
    "# Importing the NumPy library and aliasing it as 'np'\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Initialization\n",
    "\n",
    "Tensors can be initialized using a variety of methods. Consider the following examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly from data\n",
    "\n",
    "Tensors can be generated directly from data, with the data type being automatically inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Creating a nested list representing data\n",
    "data = [[1, 2], [3, 4]]\n",
    "print(f\"data as Python list:\\n{data}\")\n",
    "\n",
    "# Add blank line separating the two outputs\n",
    "print()\n",
    "\n",
    "# Converting the nested list 'data' into a PyTorch tensor\n",
    "x_data = torch.tensor(data)\n",
    "print(f\"x_data as tensor:\\n{x_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a NumPy array\n",
    "\n",
    "Tensors can be generated from NumPy arrays, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Creating a NumPy array from the existing 'data' variable\n",
    "np_array = np.array(data)\n",
    "print(f\"data as NumPy array:\\n{np_array}\")\n",
    "\n",
    "# Add blank line separating the two outputs\n",
    "print()\n",
    "\n",
    "# Converting the NumPy array 'np_array' into a PyTorch tensor using 'torch.from_numpy'\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(f\"PyTorch tensor from NumPy array:\\n{x_np}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From another tensor:\n",
    "\n",
    "The newly created tensor preserves the properties (such as shape and data type) of the input tensor, unless explicitly specified otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Creating a tensor of ones using the shape and data type of the existing tensor 'x_data'\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "# Creating a tensor of random values with the same shape as 'x_data' but with a specified \n",
    "# data type (float)\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With random or constant values:\n",
    "\n",
    "``shape`` represents a tuple of tensor dimensions. In the following functions, it dictates the dimensionality of the resulting tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Defining a tuple 'shape' representing the desired dimensions of the tensors\n",
    "shape = (2, 3,)\n",
    "\n",
    "# Creating a random tensor with the specified shape\n",
    "rand_tensor = torch.rand(shape)\n",
    "\n",
    "# Creating a tensor of ones with the specified shape\n",
    "ones_tensor = torch.ones(shape)\n",
    "\n",
    "# Creating a tensor of zeros with the specified shape\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "# Printing the random tensor\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "\n",
    "# Printing the tensor of ones\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "\n",
    "# Printing the tensor of zeros\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Attributes\n",
    "\n",
    "Tensor attributes convey information about their shape, data type, and the device where they are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Creating a random tensor with dimensions 3x4\n",
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "# Printing the shape of the tensor\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "\n",
    "# Printing the data type of the tensor\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "\n",
    "# Printing the device on which the tensor is stored\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Operations\n",
    "\n",
    "More than 100 tensor operations are available, covering tasks such as transposing, indexing, slicing, mathematical operations, linear algebra, random sampling, and more. You can find comprehensive descriptions of these operations at [PyTorch Documentation](https://pytorch.org/docs/stable/torch.html).\n",
    "\n",
    "All these operations can be executed on the GPU, often achieving higher speeds compared to running on a CPU. If you are using Colab, you can allocate a GPU by navigating to Edit > Notebook Settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Determine the optimal device for computations, prioritizing GPUs and MPS:\n",
    "DEVICE = torch.device(\n",
    "    \"cuda\"  # Prioritize GPU if available\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"  # use MPS if available\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"  # Fallback to CPU\n",
    ")\n",
    "\n",
    "# Print the selected device for clarity:\n",
    "print(f\"Torch Device: {DEVICE}\")\n",
    "\n",
    "tensor = tensor.to(DEVICE)\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with a few operations from the provided list. If you are already acquainted with the NumPy API, working with the Tensor API should be straightforward and intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard numpy-like indexing and slicing:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Creating a 4x4 tensor initialized with ones\n",
    "tensor = torch.ones(4, 4)\n",
    "\n",
    "# Modifying all elements in the second column (index 1) to be 0\n",
    "tensor[:, 1] = 0\n",
    "\n",
    "# Printing the modified tensor\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining Tensors:** Utilize `torch.cat` to concatenate a sequence of tensors along a specified dimension. For an alternative tensor joining operation with subtle differences, refer to [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Concatenating the tensor along dimension 1 (columns) three times\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "\n",
    "# Printing the result of the concatenation\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplying tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Computing the element-wise product of the tensor with itself using the 'mul' method\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "\n",
    "# Alternative syntax for element-wise multiplication using the '*' operator\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performs matrix multiplication between two tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Computing the matrix multiplication between the tensor and its transpose using the 'matmul' method\n",
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "\n",
    "# Alternative syntax for matrix multiplication using the '@' operator\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In-Place Operations:** Operations with a ``_`` suffix are in-place. For instance, ``x.copy_(y)`` or ``x.t_()`` will directly modify the tensor ``x``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Printing the original tensor\n",
    "print(tensor, \"\\n\")\n",
    "\n",
    "# In-place addition: Adding 5 to each element of the tensor using the 'add_' method\n",
    "tensor.add_(5)\n",
    "\n",
    "# Printing the tensor after the in-place addition\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>In-place operations conserve memory but can pose challenges when computing derivatives due to an immediate loss of history. Consequently, their use is discouraged.</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bridge with NumPy\n",
    "\n",
    "Tensors on the CPU and NumPy arrays can have shared underlying memory locations, so modifications to one will affect the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Creating a PyTorch tensor initialized with ones\n",
    "t = torch.ones(5)\n",
    "\n",
    "# Printing the PyTorch tensor\n",
    "print(f\"PyTorch tensor: {t}\")\n",
    "\n",
    "# Converting the PyTorch tensor 't' to a NumPy array 'n'\n",
    "n = t.numpy()\n",
    "\n",
    "# Printing the NumPy array 'n'\n",
    "print(f\"NumPy array: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any modification to the tensor is reflected in the associated NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# In-place addition: Adding 1 to each element of the \n",
    "# PyTorch tensor 't' using the 'add_' method\n",
    "t.add_(1)\n",
    "\n",
    "# Printing the modified PyTorch tensor 't'\n",
    "print(f\"PyTorch tensor: {t}\")\n",
    "\n",
    "# Printing the associated NumPy array 'n', which \n",
    "# reflects the changes made to 't'\n",
    "print(f\"NumPy array: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy array to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Creating a NumPy array initialized with ones\n",
    "n = np.ones(5)\n",
    "print(f\"NumPy array: \\n{n}\")\n",
    "\n",
    "# Converting the NumPy array 'n' to a PyTorch tensor \n",
    "# 't' using 'torch.from_numpy'\n",
    "t = torch.from_numpy(n)\n",
    "print(f\"PyTorch tensor: \\n{t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifications to the NumPy array are mirrored in the corresponding tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# In-place addition using NumPy's 'add' function: \n",
    "# Adding 1 to each element of the NumPy array 'n'\n",
    "np.add(n, 1, out=n)\n",
    "\n",
    "# Printing the PyTorch tensor 't', which reflects \n",
    "# the changes made to the NumPy array 'n'\n",
    "print(f\"PyTorch tensor: {t}\")\n",
    "\n",
    "# Printing the modified NumPy array 'n'\n",
    "print(f\"NumPy array: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
